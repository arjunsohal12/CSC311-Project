{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb8344bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import tree as treeViz\n",
        "import graphviz\n",
        "from IPython.display import display\n",
        "from dataset_reader import DataReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c44baa0",
      "metadata": {},
      "outputs": [],
      "source": [
        "file_name = \"training_data_clean.csv\"\n",
        "\n",
        "def process_multiselect(series, target_tasks):\n",
        "    \"\"\"Convert multiselect strings to lists, keeping only specified features\"\"\"\n",
        "    processed = []\n",
        "    for response in series:\n",
        "        if pd.isna(response) or response == '':\n",
        "            processed.append([])\n",
        "        else:\n",
        "            # Check which of the target tasks are present in the response\n",
        "            present_tasks = [task for task in target_tasks if task in str(response)]\n",
        "            processed.append(present_tasks)\n",
        "    return processed\n",
        "\n",
        "def extract_rating(response):\n",
        "    \"\"\"\n",
        "    Extract numeric rating from responses like '3 - Sometimes'.\n",
        "    Returns None for missing responses\n",
        "    \"\"\"\n",
        "    match = re.match(r'^(\\d+)', str(response))\n",
        "    return int(match.group(1)) if match else None\n",
        "\n",
        "def visualize_tree(model, max_depth=5):\n",
        "    \"\"\" \n",
        "    Generate and return an image representing an Sklearn decision tree.\n",
        "\n",
        "    Each node in the visualization represents a node in the decision tree.\n",
        "    In addition, visualization for each node contains:\n",
        "        - The feature that is split on\n",
        "        - The entropy (of the outputs `t`) at the node\n",
        "        - The number of training samples at the node\n",
        "        - The number of training samples with true/false values\n",
        "        - The majority class (heart disease or not)\n",
        "    The colour of the node also shows the majority class and purity\n",
        "\n",
        "    See here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
        "\n",
        "    Parameters:\n",
        "        `model` - An Sklearn decision tree model\n",
        "        `max_depth` - Max depth of decision tree to be rendered in the notebook.\n",
        "         This is useful since the tree can get very large if the max_depth is\n",
        "         set too high and thus making the resulting figure difficult to interpret.\n",
        "    \"\"\"\n",
        "    dot_data = treeViz.export_graphviz(model,\n",
        "                                       feature_names=target_tasks,\n",
        "                                       max_depth=max_depth,\n",
        "                                       class_names=['ChatGPT', 'Claude', 'Gemini'],\n",
        "                                       filled=True,\n",
        "                                       rounded=True)\n",
        "    return display(graphviz.Source(dot_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96942eaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(file_name)\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "505dbc4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "target_tasks = [\n",
        "        'Math computations',\n",
        "        'Writing or debugging code',\n",
        "        'Data processing or analysis', \n",
        "        'Explaining complex concepts simply',\n",
        "        'Converting content between formats (e.g., LaTeX)',\n",
        "        'Writing or editing essays/reports',\n",
        "        'Drafting professional text (e.g., emails, r\u00c3\u00a9sum\u00c3\u00a9s)',\n",
        "        'Brainstorming or generating creative ideas'\n",
        "    ]\n",
        "best_tasks_lists = process_multiselect(df['Which types of tasks do you feel this model handles best? (Select all that apply.)'], target_tasks)\n",
        "suboptimal_tasks_lists = process_multiselect(df['For which types of tasks do you feel this model tends to give suboptimal responses? (Select all that apply.)'], target_tasks)\n",
        "\n",
        "\n",
        "mlb_best = MultiLabelBinarizer()\n",
        "mlb_subopt = MultiLabelBinarizer()\n",
        "    \n",
        "best_tasks_encoded = mlb_best.fit_transform(best_tasks_lists)\n",
        "suboptimal_tasks_encoded = mlb_subopt.fit_transform(suboptimal_tasks_lists)\n",
        "\n",
        "# Use some rating features\n",
        "academic_numeric = df['How likely are you to use this model for academic tasks?'].apply(extract_rating)\n",
        "subopt_numeric = df['Based on your experience, how often has this model given you a response that felt suboptimal?'].apply(extract_rating)\n",
        "# Combine features\n",
        "X = np.hstack([academic_numeric.values.reshape(-1, 1), subopt_numeric.values.reshape(-1, 1), best_tasks_encoded, suboptimal_tasks_encoded])\n",
        "y = df['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279411d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "dr = DataReader(\"training_data_clean.csv\")\n",
        "X, y = dr.to_numpy()\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dab51915",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_tv, X_test, y_tv, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    #y_encoded,\n",
        "    test_size=0.1,\n",
        "    #random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_tv, y_tv, test_size=0.22) #, random_state=42\n",
        "\n",
        "print(X.shape)\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b92f8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "n_estimators = [500]\n",
        "#n_estimators = [700]\n",
        "\n",
        "for i in n_estimators:\n",
        "    print(\"Using \" + str(i) + \" trees:\")\n",
        "    #20 min split 10 min leaf performs quite well\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=i, \n",
        "        min_samples_split=20,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_valid_pred = model.predict(X_valid)\n",
        "    y_test_pred  = model.predict(X_test)\n",
        "\n",
        "    print(\"train acc:\", accuracy_score(y_train, y_train_pred))\n",
        "    print(\"valid acc:\", accuracy_score(y_valid, y_valid_pred))\n",
        "    print(\"test  acc:\", accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True) #random_state removed\n",
        "\n",
        "    cv_scores = cross_val_score(\n",
        "        model,      \n",
        "        X,           \n",
        "        y,\n",
        "        cv=skf,\n",
        "        scoring=\"accuracy\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    print(\"CV scores:\", cv_scores)\n",
        "    print(\"Mean CV acc:\", cv_scores.mean())\n",
        "    print(\"Std:\", cv_scores.std())\n",
        "    \"\"\"\n",
        "    import pickle\n",
        "    with open('best_rfc.pkl', 'wb') as f: # 'wb' for write-binary\n",
        "        pickle.dump(model, f)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "#my stuff\n",
        "#train_acc = model.score(X_train, y_train)\n",
        "#test_acc = model.score(X_test, y_test)\n",
        "\n",
        "#print(f\"Training accuracy: {train_acc:.3f}\")\n",
        "#print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51459954",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access the individual decision trees\n",
        "for i, tree in enumerate(model.estimators_):\n",
        "    print(tree.get_params())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}