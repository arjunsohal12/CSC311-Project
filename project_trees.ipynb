{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb8344bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import tree as treeViz\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "from dataset_reader import DataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c44baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"training_data_clean.csv\"\n",
    "\n",
    "def process_multiselect(series, target_tasks):\n",
    "    \"\"\"Convert multiselect strings to lists, keeping only specified features\"\"\"\n",
    "    processed = []\n",
    "    for response in series:\n",
    "        if pd.isna(response) or response == '':\n",
    "            processed.append([])\n",
    "        else:\n",
    "            # Check which of the target tasks are present in the response\n",
    "            present_tasks = [task for task in target_tasks if task in str(response)]\n",
    "            processed.append(present_tasks)\n",
    "    return processed\n",
    "\n",
    "def extract_rating(response):\n",
    "    \"\"\"\n",
    "    Extract numeric rating from responses like '3 - Sometimes'.\n",
    "    Returns None for missing responses\n",
    "    \"\"\"\n",
    "    match = re.match(r'^(\\d+)', str(response))\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def visualize_tree(model, max_depth=5):\n",
    "    \"\"\" \n",
    "    Generate and return an image representing an Sklearn decision tree.\n",
    "\n",
    "    Each node in the visualization represents a node in the decision tree.\n",
    "    In addition, visualization for each node contains:\n",
    "        - The feature that is split on\n",
    "        - The entropy (of the outputs `t`) at the node\n",
    "        - The number of training samples at the node\n",
    "        - The number of training samples with true/false values\n",
    "        - The majority class (heart disease or not)\n",
    "    The colour of the node also shows the majority class and purity\n",
    "\n",
    "    See here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
    "\n",
    "    Parameters:\n",
    "        `model` - An Sklearn decision tree model\n",
    "        `max_depth` - Max depth of decision tree to be rendered in the notebook.\n",
    "         This is useful since the tree can get very large if the max_depth is\n",
    "         set too high and thus making the resulting figure difficult to interpret.\n",
    "    \"\"\"\n",
    "    dot_data = treeViz.export_graphviz(model,\n",
    "                                       feature_names=target_tasks,\n",
    "                                       max_depth=max_depth,\n",
    "                                       class_names=['ChatGPT', 'Claude', 'Gemini'],\n",
    "                                       filled=True,\n",
    "                                       rounded=True)\n",
    "    return display(graphviz.Source(dot_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96942eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "505dbc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(734, 18)\n"
     ]
    }
   ],
   "source": [
    "target_tasks = [\n",
    "        'Math computations',\n",
    "        'Writing or debugging code',\n",
    "        'Data processing or analysis', \n",
    "        'Explaining complex concepts simply',\n",
    "        'Converting content between formats (e.g., LaTeX)',\n",
    "        'Writing or editing essays/reports',\n",
    "        'Drafting professional text (e.g., emails, résumés)',\n",
    "        'Brainstorming or generating creative ideas'\n",
    "    ]\n",
    "best_tasks_lists = process_multiselect(df['Which types of tasks do you feel this model handles best? (Select all that apply.)'], target_tasks)\n",
    "suboptimal_tasks_lists = process_multiselect(df['For which types of tasks do you feel this model tends to give suboptimal responses? (Select all that apply.)'], target_tasks)\n",
    "\n",
    "\n",
    "mlb_best = MultiLabelBinarizer()\n",
    "mlb_subopt = MultiLabelBinarizer()\n",
    "    \n",
    "best_tasks_encoded = mlb_best.fit_transform(best_tasks_lists)\n",
    "suboptimal_tasks_encoded = mlb_subopt.fit_transform(suboptimal_tasks_lists)\n",
    "\n",
    "# Use some rating features\n",
    "academic_numeric = df['How likely are you to use this model for academic tasks?'].apply(extract_rating)\n",
    "subopt_numeric = df['Based on your experience, how often has this model given you a response that felt suboptimal?'].apply(extract_rating)\n",
    "# Combine features\n",
    "X = np.hstack([academic_numeric.values.reshape(-1, 1), subopt_numeric.values.reshape(-1, 1), best_tasks_encoded, suboptimal_tasks_encoded])\n",
    "y = df['label'].values\n",
    "\n",
    "n_train = int(0.7 * len(X))\n",
    "X_train, y_train, X_test, y_test = X[:n_train], y[:n_train], X[n_train:], y[n_train:]\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279411d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(734, 6170)\n",
      "(734,)\n",
      "[0 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"dr = DataReader(\"training_data_clean.csv\")\n",
    "X, y = dr.to_numpy()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "30b92f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 300 trees:\n",
      "train acc: 0.6842105263157895\n",
      "test  acc: 0.7647058823529411\n",
      "Using 400 trees:\n",
      "train acc: 0.6881091617933723\n",
      "test  acc: 0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [300, 400]\n",
    "\n",
    "for i in n_estimators:\n",
    "    print(\"Using \" + str(i) + \" trees:\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=i, \n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10, \n",
    "        #random_state=42,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred  = model.predict(X_test)\n",
    "\n",
    "    print(\"train acc:\", accuracy_score(y_train, y_train_pred))\n",
    "    print(\"test  acc:\", accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "#my stuff\n",
    "#train_acc = model.score(X_train, y_train)\n",
    "#test_acc = model.score(X_test, y_test)\n",
    "\n",
    "#print(f\"Training accuracy: {train_acc:.3f}\")\n",
    "#print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51459954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the individual decision trees\n",
    "for i, tree in enumerate(model.estimators_):\n",
    "    print(tree.get_params())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
