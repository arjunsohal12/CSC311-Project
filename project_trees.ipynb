{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bb8344bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import tree as treeViz\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "from dataset_reader import DataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c44baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"training_data_clean.csv\"\n",
    "\n",
    "def process_multiselect(series, target_tasks):\n",
    "    \"\"\"Convert multiselect strings to lists, keeping only specified features\"\"\"\n",
    "    processed = []\n",
    "    for response in series:\n",
    "        if pd.isna(response) or response == '':\n",
    "            processed.append([])\n",
    "        else:\n",
    "            # Check which of the target tasks are present in the response\n",
    "            present_tasks = [task for task in target_tasks if task in str(response)]\n",
    "            processed.append(present_tasks)\n",
    "    return processed\n",
    "\n",
    "def extract_rating(response):\n",
    "    \"\"\"\n",
    "    Extract numeric rating from responses like '3 - Sometimes'.\n",
    "    Returns None for missing responses\n",
    "    \"\"\"\n",
    "    match = re.match(r'^(\\d+)', str(response))\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def visualize_tree(model, max_depth=5):\n",
    "    \"\"\" \n",
    "    Generate and return an image representing an Sklearn decision tree.\n",
    "\n",
    "    Each node in the visualization represents a node in the decision tree.\n",
    "    In addition, visualization for each node contains:\n",
    "        - The feature that is split on\n",
    "        - The entropy (of the outputs `t`) at the node\n",
    "        - The number of training samples at the node\n",
    "        - The number of training samples with true/false values\n",
    "        - The majority class (heart disease or not)\n",
    "    The colour of the node also shows the majority class and purity\n",
    "\n",
    "    See here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
    "\n",
    "    Parameters:\n",
    "        `model` - An Sklearn decision tree model\n",
    "        `max_depth` - Max depth of decision tree to be rendered in the notebook.\n",
    "         This is useful since the tree can get very large if the max_depth is\n",
    "         set too high and thus making the resulting figure difficult to interpret.\n",
    "    \"\"\"\n",
    "    dot_data = treeViz.export_graphviz(model,\n",
    "                                       feature_names=target_tasks,\n",
    "                                       max_depth=max_depth,\n",
    "                                       class_names=['ChatGPT', 'Claude', 'Gemini'],\n",
    "                                       filled=True,\n",
    "                                       rounded=True)\n",
    "    return display(graphviz.Source(dot_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96942eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "505dbc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(734, 18)\n",
      "(514, 18)\n",
      "(146, 18)\n",
      "(74, 18)\n"
     ]
    }
   ],
   "source": [
    "target_tasks = [\n",
    "        'Math computations',\n",
    "        'Writing or debugging code',\n",
    "        'Data processing or analysis', \n",
    "        'Explaining complex concepts simply',\n",
    "        'Converting content between formats (e.g., LaTeX)',\n",
    "        'Writing or editing essays/reports',\n",
    "        'Drafting professional text (e.g., emails, résumés)',\n",
    "        'Brainstorming or generating creative ideas'\n",
    "    ]\n",
    "best_tasks_lists = process_multiselect(df['Which types of tasks do you feel this model handles best? (Select all that apply.)'], target_tasks)\n",
    "suboptimal_tasks_lists = process_multiselect(df['For which types of tasks do you feel this model tends to give suboptimal responses? (Select all that apply.)'], target_tasks)\n",
    "\n",
    "\n",
    "mlb_best = MultiLabelBinarizer()\n",
    "mlb_subopt = MultiLabelBinarizer()\n",
    "    \n",
    "best_tasks_encoded = mlb_best.fit_transform(best_tasks_lists)\n",
    "suboptimal_tasks_encoded = mlb_subopt.fit_transform(suboptimal_tasks_lists)\n",
    "\n",
    "# Use some rating features\n",
    "academic_numeric = df['How likely are you to use this model for academic tasks?'].apply(extract_rating)\n",
    "subopt_numeric = df['Based on your experience, how often has this model given you a response that felt suboptimal?'].apply(extract_rating)\n",
    "# Combine features\n",
    "X = np.hstack([academic_numeric.values.reshape(-1, 1), subopt_numeric.values.reshape(-1, 1), best_tasks_encoded, suboptimal_tasks_encoded])\n",
    "y = df['label'].values\n",
    "\n",
    "X_tv, X_test, y_tv, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tv, y_tv, test_size=0.22, random_state=42)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279411d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(734, 6170)\n",
      "(734,)\n",
      "[0 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"dr = DataReader(\"training_data_clean.csv\")\n",
    "X, y = dr.to_numpy()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "30b92f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 trees:\n",
      "train acc: 0.7354085603112841\n",
      "valid acc: 0.6506849315068494\n",
      "test  acc: 0.7162162162162162\n",
      "CV scores: [0.63265306 0.67346939 0.6122449  0.71428571 0.69178082]\n",
      "Mean CV acc: 0.6648867766284596\n",
      "Std: 0.03754300394485482\n",
      "Using 300 trees:\n",
      "train acc: 0.7315175097276264\n",
      "valid acc: 0.6575342465753424\n",
      "test  acc: 0.7162162162162162\n",
      "CV scores: [0.63945578 0.70068027 0.70748299 0.63265306 0.66438356]\n",
      "Mean CV acc: 0.6689311340974745\n",
      "Std: 0.030658861537694926\n",
      "Using 400 trees:\n",
      "train acc: 0.7334630350194552\n",
      "valid acc: 0.6575342465753424\n",
      "test  acc: 0.7297297297297297\n",
      "CV scores: [0.7414966  0.63945578 0.65306122 0.70068027 0.6369863 ]\n",
      "Mean CV acc: 0.6743360357841767\n",
      "Std: 0.04066647840474468\n",
      "Using 500 trees:\n",
      "train acc: 0.7373540856031129\n",
      "valid acc: 0.6575342465753424\n",
      "test  acc: 0.7162162162162162\n",
      "CV scores: [0.72108844 0.70748299 0.68027211 0.6122449  0.64383562]\n",
      "Mean CV acc: 0.6729848103625012\n",
      "Std: 0.0402397826597134\n",
      "Using 600 trees:\n",
      "train acc: 0.7354085603112841\n",
      "valid acc: 0.6575342465753424\n",
      "test  acc: 0.7297297297297297\n",
      "CV scores: [0.7414966  0.67346939 0.70068027 0.63265306 0.62328767]\n",
      "Mean CV acc: 0.6743173981921535\n",
      "Std: 0.04370060691587894\n",
      "Using 700 trees:\n",
      "train acc: 0.7334630350194552\n",
      "valid acc: 0.6575342465753424\n",
      "test  acc: 0.7432432432432432\n",
      "CV scores: [0.68027211 0.68707483 0.69387755 0.65986395 0.64383562]\n",
      "Mean CV acc: 0.6729848103625011\n",
      "Std: 0.01849309374838548\n",
      "Using 800 trees:\n",
      "train acc: 0.7295719844357976\n",
      "valid acc: 0.6643835616438356\n",
      "test  acc: 0.7297297297297297\n",
      "CV scores: [0.71428571 0.67346939 0.61904762 0.68707483 0.62328767]\n",
      "Mean CV acc: 0.6634330444506571\n",
      "Std: 0.036952329333956986\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [200, 300, 400, 500, 600, 700, 800]\n",
    "#n_estimators = [700]\n",
    "\n",
    "for i in n_estimators:\n",
    "    print(\"Using \" + str(i) + \" trees:\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=i, \n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=5,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    y_test_pred  = model.predict(X_test)\n",
    "\n",
    "    print(\"train acc:\", accuracy_score(y_train, y_train_pred))\n",
    "    print(\"valid acc:\", accuracy_score(y_valid, y_valid_pred))\n",
    "    print(\"test  acc:\", accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True) #random_state removed\n",
    "\n",
    "    cv_scores = cross_val_score(\n",
    "        model,      \n",
    "        X,           \n",
    "        y,\n",
    "        cv=skf,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(\"CV scores:\", cv_scores)\n",
    "    print(\"Mean CV acc:\", cv_scores.mean())\n",
    "    print(\"Std:\", cv_scores.std())\n",
    "\n",
    "\n",
    "\n",
    "#my stuff\n",
    "#train_acc = model.score(X_train, y_train)\n",
    "#test_acc = model.score(X_test, y_test)\n",
    "\n",
    "#print(f\"Training accuracy: {train_acc:.3f}\")\n",
    "#print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51459954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the individual decision trees\n",
    "for i, tree in enumerate(model.estimators_):\n",
    "    print(tree.get_params())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
